# -*- coding: utf-8 -*-
"""Insurance_fraudd.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iHzhkpoUGHLvze1In3xnhaSknl7eC9sD

**Dataset :**
"""

import pandas as pd
import numpy as pandas
data=pd.read_csv('fraud_oracle.csv')
data

data.head()

pd.options.display.max_columns = None
data.head()

data.tail()

"""**Target Function**"""

data["FraudFound_P"].value_counts()

"""**Visualization by histg**"""

data.hist(bins=30,figsize=(30,30))

"""**Data for training and testing**"""

train = data[:int(0.7 * len(data))]  # 70% for training
test = data[int(0.7 * len(data)):int(0.85 * len(data))]  # 15% for testing
val = data[int(0.85 * len(data)):]  # Remaining 15% for validation


train['FraudFound_P'].value_counts(), test['FraudFound_P'].value_counts(), val['FraudFound_P'].value_counts()

"""**Splitting data ,Train,Test**"""

data = pd.read_csv('fraud_oracle.csv')

categorical_features = ['Month', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed',
                        'MonthClaimed', 'Sex', 'MaritalStatus', 'Fault', 'PolicyType',
                        'VehicleCategory', 'VehiclePrice', 'Days_Policy_Accident',
                        'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle',
                        'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent',
                        'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim',
                        'NumberOfCars', 'BasePolicy']

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoder.fit(data.loc[:, categorical_features])
encoded_features = encoder.transform(data.loc[:, categorical_features])
encoded_data = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))

numerical_features = ['WeekOfMonth', 'WeekOfMonthClaimed', 'Age', 'Deductible',
                      'DriverRating', 'RepNumber']
final_data = pd.concat([data[numerical_features], encoded_data, data['FraudFound_P']], axis=1)


X = final_data.drop(columns=['FraudFound_P'])
y = final_data['FraudFound_P']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


scaler = StandardScaler()
X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])
X_test[numerical_features] = scaler.transform(X_test[numerical_features])

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler

data = pd.read_csv('fraud_oracle.csv')

categorical_features = ['Month', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed',
                        'MonthClaimed', 'Sex', 'MaritalStatus', 'Fault', 'PolicyType',
                        'VehicleCategory', 'VehiclePrice', 'Days_Policy_Accident',
                        'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle',
                        'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent',
                        'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim',
                        'NumberOfCars', 'BasePolicy']

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoder.fit(data.loc[:, categorical_features])
encoded_features = encoder.transform(data.loc[:, categorical_features])

encoded_data = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))

numerical_features = ['WeekOfMonth', 'WeekOfMonthClaimed', 'Age', 'Deductible',
                      'DriverRating', 'RepNumber']

final_data = pd.concat([data[numerical_features], encoded_data, data['FraudFound_P']], axis=1)

X = final_data.drop(columns=['FraudFound_P'])
y = final_data['FraudFound_P']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])
X_test[numerical_features] = scaler.transform(X_test[numerical_features])

"""**Logistic Regression**"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
mo = LogisticRegression(max_iter=1000)
mo.fit(X_train, y_train)


y_pred = mo.predict(X_test)
print(classification_report(y_test, y_pred, target_names=['Not Fraud', 'Fraud']))

"""**RandomForest Classifier**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred,target_names=['Not Fraud', 'Fraud']))

"""**GradientBoosting Classifier**"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split

model = GradientBoostingClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred, target_names=['Not Fraud', 'Fraud']))  # Print the report

"""**Analysing and visualization of models efficiency**"""

from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

def get_classification_report(y_test, y_pred):
    report = classification_report(y_test, y_pred, target_names=['Not Fraud', 'Fraud'], output_dict=True)
    return {
        "Model": "",
        "Accuracy": report['accuracy'],
        "Precision (Fraud)": report['Fraud']['precision'],
        "Recall (Fraud)": report['Fraud']['recall'],
        "F1-Score (Fraud)": report['Fraud']['f1-score']
    }

results = []

# Logistic Regression
mo = LogisticRegression(max_iter=1000)
mo.fit(X_train, y_train)
y_pred = mo.predict(X_test)
logistic_report = get_classification_report(y_test, y_pred)
logistic_report["Model"] = "Logistic Regression"
results.append(logistic_report)

# Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
rf_report = get_classification_report(y_test, y_pred)
rf_report["Model"] = "Random Forest"
results.append(rf_report)

# Gradient Boosting
gb = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb.fit(X_train, y_train)
y_pred = gb.predict(X_test)
gb_report = get_classification_report(y_test, y_pred)
gb_report["Model"] = "Gradient Boosting"
results.append(gb_report)

results_df = pd.DataFrame(results)

plot_size = (6, 4)
metrics = ["Accuracy", "Precision (Fraud)", "Recall (Fraud)", "F1-Score (Fraud)"]

for metric in metrics:
    plt.figure(figsize=plot_size)
    sns.barplot(data=results_df, x="Model", y=metric)
    plt.title(f'{metric} Comparison')
    plt.show()

"""**Saving the model by training on whole data for production**"""

categorical_features = ['Month', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed',
                        'MonthClaimed', 'Sex', 'MaritalStatus', 'Fault', 'PolicyType',
                        'VehicleCategory', 'VehiclePrice', 'Days_Policy_Accident',
                        'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle',
                        'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent',
                        'AgentType', 'NumberOfSuppliments', 'AddressChange_Claim',
                        'NumberOfCars', 'BasePolicy']

numerical_features = ['WeekOfMonth', 'WeekOfMonthClaimed', 'Age', 'Deductible',
                      'DriverRating', 'RepNumber']

final_data = pd.concat([train, test, val], ignore_index=True)

encoded_features = encoder.transform(final_data[categorical_features])
encoded_data = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))

final_X = pd.concat([final_data[numerical_features], encoded_data], axis=1)
final_y = final_data['FraudFound_P']

final_X[numerical_features] = scaler.transform(final_X[numerical_features])

# Train the final model
final_model = RandomForestClassifier(n_estimators=100, random_state=42)
final_model.fit(final_X, final_y)

"""**Predicting Output**"""

import pandas as pd

new_data = pd.DataFrame(
  {
    "Month": ["Jul"],
    "DayOfWeek": ["Saturday"],
    "Make": ["Honda"],
    "AccidentArea": ["Urban"],
    "DayOfWeekClaimed": ["Tuesday"],
    "MonthClaimed": ["Sep"],
    "Sex": ["Male"],
    "MaritalStatus": ["Single"],
    "Fault": ["Policy Holder"],
    "PolicyType": ["Sedan - All Perils"],
    "VehicleCategory": ["Sedan"],
    "VehiclePrice": ["more than 69000"],
    "Days_Policy_Accident": ["more than 30"],
    "Days_Policy_Claim": ["more than 30"],
    "PastNumberOfClaims": ["none"],
    "AgeOfVehicle": ["new"],
    "AgeOfPolicyHolder": ["16 to 17"],
    "PoliceReportFiled": ["No"],
    "WitnessPresent": ["No"],
    "AgentType": ["External"],
    "NumberOfSuppliments": ["none"],
    "AddressChange_Claim": ["no change"],
    "NumberOfCars": ["1 vehicle"],
    "BasePolicy": ["All Perils"],
    "WeekOfMonth": [1],
    "WeekOfMonthClaimed": [4],
    "Age": [0],
    "Deductible": [400],
    "DriverRating": [1],
    "RepNumber": [9]
}
)

for col in categorical_features:
    new_data[col] = new_data[col].astype(str)  # Convert to string type if necessary

encoded_new_data = encoder.transform(new_data[categorical_features])
encoded_new_data_df = pd.DataFrame(encoded_new_data, columns=encoder.get_feature_names_out(categorical_features))

new_data_final = pd.concat([new_data[numerical_features], encoded_new_data_df], axis=1)

new_data_final[numerical_features] = scaler.transform(new_data_final[numerical_features])

predictions = final_model.predict(new_data_final)

if predictions[0] == 1:
    print("Prediction: Fraud")
else:
    print("Prediction: Not Fraud")